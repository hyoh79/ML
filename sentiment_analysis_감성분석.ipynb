{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "sentiment analysis 감성분석.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyoh79/ML/blob/main/sentiment_analysis_%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "valued-label",
        "outputId": "5bc3244d-440c-44c8-b882-2073b29d4fdf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "import scipy as sp\n",
        "import matplotlib as mpl"
      ],
      "id": "valued-label",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "japanese-mercury",
        "outputId": "7ba4b3b1-25c0-4f77-f8dd-2e8eaeb02c8f"
      },
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "\n",
        "url1 = 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt'\n",
        "wget.download(url1)"
      ],
      "id": "japanese-mercury",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=31a57590d94033db77fa2b70a7c04c8d9c34d2f82fbc7210d4239e4f477d159c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ratings_train.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "formed-russian",
        "outputId": "e71eead3-0101-4ccd-aac8-c49fe3e3e858"
      },
      "source": [
        "url2 = 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt'\n",
        "wget.download(url2)"
      ],
      "id": "formed-russian",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ratings_test.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "legendary-harvest"
      },
      "source": [
        "import codecs\n",
        "\n",
        "with codecs.open(\"ratings_train.txt\", encoding='utf-8') as f:\n",
        "    data = [line.split('\\t') for line in f.read().splitlines()]\n",
        "    data = data[1:]   # header 제외"
      ],
      "id": "legendary-harvest",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reserved-competition",
        "outputId": "c52fa4f7-7d80-4337-889e-ef4d6fe4a9e6"
      },
      "source": [
        "from pprint import pprint\n",
        "pprint(data[0])"
      ],
      "id": "reserved-competition",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mighty-medication"
      },
      "source": [
        "X = list(zip(*data))[1]\n",
        "y = np.array(list(zip(*data))[2], dtype=int)"
      ],
      "id": "mighty-medication",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "median-variance"
      },
      "source": [
        "# 데이터를 다항 나이브 베이즈 모형으로 학습"
      ],
      "id": "median-variance",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "creative-illinois"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model1 = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('mb', MultinomialNB()),\n",
        "])"
      ],
      "id": "creative-illinois",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atomic-going",
        "outputId": "584b7cc7-d203-4493-9a53-df1fffc5c3e6"
      },
      "source": [
        "model1.fit(X, y)"
      ],
      "id": "atomic-going",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('mb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "australian-madonna"
      },
      "source": [
        "import codecs\n",
        "with codecs.open(\"ratings_test.txt\", encoding='utf-8') as f:\n",
        "    data_test = [line.split('\\t') for line in f.read().splitlines()]\n",
        "    data_test = data_test[1:]   # header 제외"
      ],
      "id": "australian-madonna",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prerequisite-bumper",
        "outputId": "f3cce39d-fe35-4d87-8845-20b5d67c7003"
      },
      "source": [
        "X_test = list(zip(*data_test))[1]\n",
        "y_test = np.array(list(zip(*data_test))[2], dtype=int)\n",
        "\n",
        "print(classification_report(y_test, model1.predict(X_test)))"
      ],
      "id": "prerequisite-bumper",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.84      0.83     24827\n",
            "           1       0.84      0.81      0.82     25173\n",
            "\n",
            "    accuracy                           0.83     50000\n",
            "   macro avg       0.83      0.83      0.83     50000\n",
            "weighted avg       0.83      0.83      0.83     50000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unlimited-louis"
      },
      "source": [
        "# Tfidf 방법을 사용했을 때와 비교"
      ],
      "id": "unlimited-louis",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drawn-composite"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "model2 = Pipeline([\n",
        "    ('vect', TfidfVectorizer()),\n",
        "    ('mb', MultinomialNB()),\n",
        "])"
      ],
      "id": "drawn-composite",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "regular-buyer",
        "outputId": "653067ba-a95b-48f0-f1d0-aeddd273dc13"
      },
      "source": [
        "model2.fit(X, y)"
      ],
      "id": "regular-buyer",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('mb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spare-rebecca",
        "outputId": "d6f8b990-0e0c-4ff2-f86c-185702d66085"
      },
      "source": [
        "print(classification_report(y_test, model2.predict(X_test)))"
      ],
      "id": "spare-rebecca",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.84      0.83     24827\n",
            "           1       0.84      0.81      0.83     25173\n",
            "\n",
            "    accuracy                           0.83     50000\n",
            "   macro avg       0.83      0.83      0.83     50000\n",
            "weighted avg       0.83      0.83      0.83     50000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "indirect-better"
      },
      "source": [
        "# 형태소 분석기를 사용한 결과와 비교"
      ],
      "id": "indirect-better",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agricultural-mirror",
        "outputId": "ac8059de-6907-44c4-e2fc-ec196dd6fdb7"
      },
      "source": [
        "!pip install konlpy\n",
        "from konlpy.tag import Okt\n",
        "pos_tagger = Okt()\n",
        "\n",
        "def tokenize_pos(doc):\n",
        "    return ['/'.join(t) for t in pos_tagger.pos(doc)]"
      ],
      "id": "agricultural-mirror",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "organic-portal"
      },
      "source": [
        "model3 = Pipeline([\n",
        "    ('vect', CountVectorizer(tokenizer=tokenize_pos)),\n",
        "    ('mb', MultinomialNB()),\n",
        "])"
      ],
      "id": "organic-portal",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "violent-august",
        "outputId": "1776115f-0dd5-4abc-9c62-f9dcc749dbd7"
      },
      "source": [
        "model3.fit(X, y)"
      ],
      "id": "violent-august",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_pos at 0x7f51d27375f0>,\n",
              "                                 vocabulary=None)),\n",
              "                ('mb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "norwegian-sensitivity",
        "outputId": "d287d6c2-e81b-4392-dc79-470086e1e668"
      },
      "source": [
        "print(classification_report(y_test, model3.predict(X_test)))"
      ],
      "id": "norwegian-sensitivity",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85     24827\n",
            "           1       0.86      0.85      0.85     25173\n",
            "\n",
            "    accuracy                           0.85     50000\n",
            "   macro avg       0.85      0.85      0.85     50000\n",
            "weighted avg       0.85      0.85      0.85     50000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "central-scanning"
      },
      "source": [
        "# (1,2)-gram 을 사용하면 성능이 더 개선"
      ],
      "id": "central-scanning",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dried-biodiversity"
      },
      "source": [
        "model4 = Pipeline([\n",
        "    ('vect', TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1, 2))),\n",
        "    ('mb', MultinomialNB()),\n",
        "])"
      ],
      "id": "dried-biodiversity",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swedish-wagon",
        "outputId": "97c58958-eb04-4df9-fd48-ecd4458673cf"
      },
      "source": [
        "model4.fit(X, y)"
      ],
      "id": "swedish-wagon",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_pos at 0x7f51d27375f0>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('mb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "personalized-amsterdam",
        "outputId": "2fed4903-0353-423e-ac96-6357eb417694"
      },
      "source": [
        "print(classification_report(y_test, model4.predict(X_test)))"
      ],
      "id": "personalized-amsterdam",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87     24827\n",
            "           1       0.87      0.86      0.87     25173\n",
            "\n",
            "    accuracy                           0.87     50000\n",
            "   macro avg       0.87      0.87      0.87     50000\n",
            "weighted avg       0.87      0.87      0.87     50000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "comfortable-street"
      },
      "source": [
        ""
      ],
      "id": "comfortable-street",
      "execution_count": null,
      "outputs": []
    }
  ]
}