{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "USL_PCA.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvIzfuzfjZWAMgGxfBxynr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyoh79/ML/blob/main/USL_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49dyFgkpoHAE"
      },
      "source": [
        "!pip install mglearn\n",
        "import mglearn\n",
        "# [Example1 of PCA] 다음 그림은 인위적으로 만든 2차원 데이터셋을 사용하여 PCA효과를 나타낸 것\n",
        "mglearn.plots.plot_pca_illustration()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4PqOZ4koQgE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig,axes=plt.subplots(15,2,figsize=(10,20))\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer=load_breast_cancer()\n",
        "malignant=cancer.data[cancer.target==0]\n",
        "benign=cancer.data[cancer.target==1]\n",
        "\n",
        "ax=axes.ravel()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsbUVgSt2eiU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2yNZWzEqu-M"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "fig,axes=plt.subplots(15,2,figsize=(10,20))\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer=load_breast_cancer()\n",
        "malignant=cancer.data[cancer.target==0]\n",
        "benign=cancer.data[cancer.target==1]\n",
        "\n",
        "ax=axes.ravel()\n",
        "\n",
        "for i in range(30):\n",
        "  _,bins=np.histogram(cancer.data[:,i],bins=50)\n",
        "  ax[i].hist(malignant[:,i],bins=bins,color=mglearn.cm3(0),alpha=.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOj20Gz6pkxL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECIGQpTLsp2X"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "fig,axes=plt.subplots(15,2,figsize=(10,20))\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer=load_breast_cancer()\n",
        "malignant=cancer.data[cancer.target==0]\n",
        "benign=cancer.data[cancer.target==1]\n",
        "\n",
        "ax=axes.ravel()\n",
        "\n",
        "for i in range(30):\n",
        "  _,bins=np.histogram(cancer.data[:,i],bins=50)\n",
        "  ax[i].hist(malignant[:,i],bins=bins,color=mglearn.cm3(0),alpha=.5)\n",
        "  ax[i].hist(benign[:,i],bins=bins,color=mglearn.cm3(2),alpha=.5)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4mNgFI9tDVS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "fig,axes=plt.subplots(15,2,figsize=(10,20))\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer=load_breast_cancer()\n",
        "malignant=cancer.data[cancer.target==0]\n",
        "benign=cancer.data[cancer.target==1]\n",
        "\n",
        "ax=axes.ravel()\n",
        "\n",
        "for i in range(30):\n",
        "  _,bins=np.histogram(cancer.data[:,i],bins=50)\n",
        "  ax[i].hist(malignant[:,i],bins=bins,color=mglearn.cm3(0),alpha=.5)\n",
        "  ax[i].hist(benign[:,i],bins=bins,color=mglearn.cm3(0),alpha=.5)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKMD0SDiszLH"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "fig,axes=plt.subplots(15,2,figsize=(10,20))\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer=load_breast_cancer()\n",
        "malignant=cancer.data[cancer.target==0]\n",
        "benign=cancer.data[cancer.target==1]\n",
        "\n",
        "ax=axes.ravel()\n",
        "\n",
        "for i in range(30):\n",
        "  _,bins=np.histogram(cancer.data[:,i],bins=50)\n",
        "  ax[i].hist(malignant[:,i],bins=bins,color=mglearn.cm3(0),alpha=.5)\n",
        "  ax[i].hist(benign[:,i],bins=bins,color=mglearn.cm3(2),alpha=.5)\n",
        "  ax[i].set_title(cancer.feature_names[i])\n",
        "  ax[i].set_yticks(())\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syOsOQEutxc8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "fig,axes=plt.subplots(15,2,figsize=(10,20))\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer=load_breast_cancer()\n",
        "malignant=cancer.data[cancer.target==0]\n",
        "benign=cancer.data[cancer.target==1]\n",
        "\n",
        "ax=axes.ravel()\n",
        "\n",
        "for i in range(30):\n",
        "  # 각 특성에 대한 히스토그램으로 특정 간격(bin이라고 부름)에 얼마나 많은 데이터 포인트가 나타나는지 횟수를 센 것\n",
        "  _,bins=np.histogram(cancer.data[:,i],bins=50)\n",
        "  ax[i].hist(malignant[:,i],bins=bins,color=mglearn.cm3(0),alpha=.5)\n",
        "  ax[i].hist(benign[:,i],bins=bins,color=mglearn.cm3(2),alpha=.5)\n",
        "  ax[i].set_title(cancer.feature_names[i])\n",
        "  ax[i].set_yticks(())\n",
        "  \n",
        "ax[0].set_xlabel(\"Feature Size\")\n",
        "ax[0].set_ylabel(\"Frequency\")\n",
        "ax[0].legend([\"malignant\",\"benign\"],loc=\"best\")\n",
        "fig.tight_layout()\n",
        "# 각 그래프는 히스토그램 두 개를 겹쳐놓은 것으로 초록색은 양성 클래스의 포인트를, 푸른색은 악성 클래스의 포인트를 나타냄.\n",
        "# 특성들이 클래스별로 어떻게 분포되어 있는지를 알려주고, 이를 통해 어떤 특성이 양성과 악성 샘플을 구분하는데 더 좋은지 가늠해볼 수 있음.\n",
        "# 예) \"smoothness error\"특성은 두 히스토그램이 거의 겹쳐져 별로 쓸모가 없음. \n",
        "# 예) \"worst concave points\"는 두 히스토그램이 확실히 구분되어 매우 유용한 특성임."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lzSnfKGtX5a"
      },
      "source": [
        "# [Example2 of PCA] \n",
        "\n",
        "# PCA를 사용하면 특성간 주요 상호작용이나 이 상호작용이 클래스와 어떤 관련이 있는지 찾아낼 수 있기 때문에 2차원 시각화도 가능\n",
        "# 예) 처음 두 개의 주성분을 찾아 2차원 공간에 하나의 산점도로 데이터를 시각화해볼 수 있음.\n",
        "# PCA를 적용하려면 특성의 스케일이 서로 다르면 올바른 주성분 방향을 찾을 수 없으니 표쥰값으로 변환/스케일을 조정해야함.\n",
        "# 예) StandardScaler - 각 특성의 분산이 1이 되도록 함.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(cancer.data)\n",
        "X_scaled=scaler.transform(cancer.data)\n",
        "X_scaled\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca=PCA(n_components=2) #데이터의 처음 두 개 주성분만 유지시킴\n",
        "pca.fit(X_scaled) # cancer data로 PCA모델을 만듬\n",
        "X_pca=pca.transform(X_scaled) # 처음 두 개의 주성분을 사용해 데이터를 변환\n",
        "\n",
        "print(\"원본 데이터 형태:\", str(X_scaled.shape))\n",
        "print(\"축소된 데이터 형태:\", str(X_pca.shape))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "!pip install mglearn\n",
        "import mglearn\n",
        "mglearn.discrete_scatter(X_pca[:,0],X_pca[:,1],cancer.target)\n",
        "\n",
        "plt.legend([\"malignant\",\"benign\"],loc=\"best\")\n",
        "plt.gca().set_aspect(\"equal\")\n",
        "plt.xlabel(\"PCA1\")\n",
        "plt.ylabel(\"PCA2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZcrNcIiEt2k"
      },
      "source": [
        "print(\"PCA 주성분 형태:\", pca.components_.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeLU8KhWbq4A"
      },
      "source": [
        "print(\"PCA 주성분 형태:\", pca.components_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5-4mKwkbvH8"
      },
      "source": [
        "plt.matshow(pca.components_,cmap='viridis')\n",
        "plt.yticks([0,1],[\"PCA1\",\"PCA2\"])\n",
        "plt.colorbar()\n",
        "plt.xticks(range(len(cancer.feature_names)),cancer.feature_names,rotation=60,ha='left')\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"PCA\")\n",
        "# PCA1의 모든 특성은 부호가 같음. (모두 양수라서 모든 특성 사이에 공통된 상호관계가 있다는 뜻이지만, \n",
        "# 앞서 언급한 대로 PCA의 화살표 방향은 의미가 없음.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqQGNfKZcFI4"
      },
      "source": [
        "# [Example3 of PCA]\n",
        "from sklearn.datasets import fetch_lfw_people \n",
        "people=fetch_lfw_people(min_faces_per_person=20, resize=0.7)\n",
        "#print(\"people:\", people)\n",
        "print(\"people.DESCR\",people.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "272Pj9tuqnMv"
      },
      "source": [
        "\n",
        "\n",
        "fig,axes=plt.subplots(2,5,figsize=(15,8),subplot_kw={'xticks':(), 'yticks':()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnncmu4ArKDv"
      },
      "source": [
        "for target,image,ax in zip(people.target,people.images, axes.ravel()):\n",
        "  ax.imshow(image)\n",
        "  ax.set_title(people.target_names[target])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MFFW8CnriRw"
      },
      "source": [
        "fig,axes=plt.subplots(2,5,figsize=(15,8),subplot_kw={'xticks':(), 'yticks':()})\n",
        "for target,image,ax in zip(people.target,people.images, axes.ravel()):\n",
        "  ax.imshow(image)\n",
        "  ax.set_title(people.target_names[target])\n",
        "# 62명의 얼굴을 찍은 이미지가 총 3,023개가 있으며 각 이미지의 크기는 87x65픽셀\n",
        "print(\"people.images.shape:\", people.images.shape)\n",
        "print(\"클래스 개수:\", len(people.target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Gmz7EerlQZ"
      },
      "source": [
        "# 각 타깃이 나타난 횟수 계산\n",
        "counts=np.bincount(people.target)\n",
        "\n",
        "# 타깃별 이름과 횟수 출력\n",
        "for i, (count,name) in enumerate(zip(counts,people.target_names)):\n",
        "  print(\"{0:25} {1:3}\".format(name,count),end='    ')\n",
        "  if(i+1) %3 == 0:\n",
        "    print()\n",
        "\n",
        "# 이 데이터셋은 조금 편중되어 있어서 다음과 같이 조지 부시와 콜린 파월의 이미지가 많음.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iwx8I2ovl9m"
      },
      "source": [
        "\n",
        "\n",
        "# 총 3023개의 이미지를 쉽게 다루기 위한 mask변수를 모두 False로 초기화\n",
        "mask=np.zeros(people.target.shape,dtype=np.bool)\n",
        "print(\"mask:\", mask)\n",
        "print(\"mask.shape:\", mask.shape)\n",
        "# 3023개의 각 이미지의 라벨(클래스, 예: 62명의 얼굴, 0~61사이의 숫자)를 출력후 확인\n",
        "print(people.target)\n",
        "print(people.target.shape)\n",
        "#print(people.target_names)\n",
        "\n",
        "# # 총 3,023개의 이미지에서 중복되는 경우는 제외하고 62명의 얼굴만 추려냄\n",
        "for target in np.unique(people.target):\n",
        "  #print(\"target in for loop\",target)\n",
        "  # 데이터의 편중을 없애기 위해서 사람마다 50개의 이미지만 선택.\n",
        "  # 이렇게 하지 않으면, 조시 부시에 치우친 특성만 추출됨.\n",
        "  mask[np.where(people.target==target)[0][:50]] = 1\n",
        "\n",
        "print(\"mask:\", mask)\n",
        "X_people=people.data[mask]\n",
        "print(\"X_people:\", X_people)\n",
        "print(\"X_people.shape\", X_people.shape)\n",
        "\n",
        "y_people=people.target[mask]\n",
        "print(\"y_people:\", y_people)\n",
        "print(\"y_people.shape\", y_people.shape)\n",
        "\n",
        "# 0~255 사이의 흑백 이미지의 픽셀 값을 0~1 스케일로 조정함.\n",
        "# MinMaxScaler를 적용하는 것과 같은 효과를 냄\n",
        "X_people=X_people/255.\n",
        "\n",
        "print(\"X_people/255:\", X_people)\n",
        "print(\"X_people/255.shape\", X_people.shape)\n",
        "\n",
        "# 얼굴인식이라 하면 통상적으로 새로운 얼굴 이미지가 데이터베이스에 있는 기존 얼굴 중 하나에 속하는지 찻는 것\n",
        "# 예) 사진 애플리케이션, 소셜 미디어, 보안 애플리케이션등\n",
        "# 해결책1) 각 사람을 서로 다른 클래스로 구분하는 분류기를 만드는 것 --> 하지만 각 사람에 대한 이미지가 부족\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFvnJGkp0TLy"
      },
      "source": [
        "# 해결책2) 대규모 모델을 다시 훈련시키지 않고도 새로운 사람의 얼굴을 쉽게 추가할 수 있어야 함. \n",
        "# -- 분류하려는 얼굴과 가장 비슷한 얼굴 이미지를 찾는 1-최근접 이웃 분류기를 사용\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_people,y_people,stratify=y_people, random_state=0)\n",
        "\n",
        "knn=KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X_train,y_train)\n",
        "print(\"1-최근접 이웃의 테스트 세트 점수: {:.2f}\".format(knn.score(X_test,y_test)))\n",
        "\n",
        "# 결과: 정확도가 23%, 클래스 62개를 분류하는 문제에서 아주 나쁜 결과는 아니지만 (예: 무작위로 분류시 정확도- 1/62=1.6%)\n",
        "# 그렇다고 매우 좋은 결과도 아님. 4번에 1번 꼴로만 올바르게 분류되는 수준...\n",
        "\n",
        "# 또한, 얼굴의 유사도를 측정하기 위해 원본 픽셀 공간에서 계산하는 것 \n",
        "# (예: 픽셀을 사용해서 2개의 이미지 비교- 각 픽셀의 회색톤 값을 다른 이미지에서 동일한 위치에 있는 픽셀값과 비교 시) 한계점존재\n",
        "# [1] 픽셀 비교시 얼굴 위치가 한 픽셀만 오른쪽으로 이동해도 큰 차이를 만듬. --> 완전 다른 얼굴로 인식될 수 있음.\n",
        "# [2] 픽셀 비교는 사람이 얼굴 이미지 인식하는 것과 많이 다르고 픽셀비교로 얼굴의 특징을 찾아내기 어려움\n",
        "\n",
        "# 결과, PCA으로 변환하여 거리를 계산하면 정확도가 높아질것으로 예상됨.\n",
        "# 예) PCA의 화이트닝(whitening, 백색화 옵션)을 사용하여 PCA의 스케일이 같아지도록 조정함. (StandardScaler와 같은 효과)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laQ85lUyx_ip"
      },
      "source": [
        "# PCA whitening 시각화\n",
        "mglearn.plots.plot_pca_whitening()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWNe9IB__Gs8"
      },
      "source": [
        "# PCA객체를 훈련 데이터로 학습시켜서 처음 100개의 주성분을 추출\n",
        "pca=PCA(n_components=100,whiten=True,random_state=0).fit(X_train)\n",
        "# 주성분으로 변환된 훈련데이터와 테스트데이터를 반환\n",
        "X_train_pca=pca.transform(X_train)\n",
        "X_test_pca=pca.transform(X_test)\n",
        "\n",
        "print(\"X_train_pca.shape:\",X_train_pca.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf3BIQLX_nvK"
      },
      "source": [
        " # 새 데이터는 처음 100개의 주성분에 해당되는 특성을 가지고 있기에 해당 데이터를 활용하여\n",
        " # kNN으로 이미지를 분류\n",
        " knn=KNeighborsClassifier(n_neighbors=1)\n",
        " knn.fit(X_train_pca,y_train)\n",
        " print(\"테스트 세트 정확도:{:.2f}\".format(knn.score(X_test_pca,y_test)))\n",
        " # 모델의 정확도가 23%에서 31%로 크게 향상되었으므로 주성분이 데이터를 더 잘 표현한다고 판단"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NmQzWbJEA3_"
      },
      "source": [
        "# 주성분 해석1) 주성분은 원본 데이터에 있는/입력 데이터 공간\n",
        "# (i.e., 입력 차원: 87x65=5,655픽셀의 흑백 이미지, 5,655개의 각 픽셀은 0~1사이의 회색톤 값을 가지고 있는 하나의 차원)\n",
        "# 에서의 어떤 방향이기에 87x65=5,655픽셀의 흑백 이미지이고, 대응하는 여러 특성이 조합된 형태이기에 매우 복잡\n",
        "# 하지만, 이미지 데이터일 경우엔 계산한 주성분을 쉽게 시각화해볼 수 있음\n",
        "# 몇 개의 주성분을 시각화\n",
        "print(\"pca.components_.shape\",pca.components_.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-4yFq67HgNu"
      },
      "source": [
        "fig,axes=plt.subplots(3,5,figsize=(15,12),subplot_kw={'xticks':(),'yticks':()})\n",
        "for i, (component,ax) in enumerate(zip(pca.components_,axes.ravel())):\n",
        "  ax.imshow(component.reshape(image.shape),cmap='viridis')\n",
        "  ax.set_title(\"PCA{}\".format((i+1)))\n",
        "\n",
        "# 시각화를 통해서 살펴본 주성분을 완전하게 이해할 순 없지만 몇몇 주성분이 잡아낸 얼굴 이미지의 특징을 짐작해볼 수 있음.\n",
        "# 예) PCA1 - 얼굴과 배경의 명암 차이를 기록한 것으로 보임.\n",
        "# 예) PCA2 - 오른쪽과 왼쪽 조명의 차이를 담고 있는 것으로 보임.\n",
        "# PCA모델기반 픽셀은 원본 픽셀 값을 사용하는 것보다는 의미가 있지만 여전히 사람의 방식과는 차이가 큼."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm0I9pgUIgxp"
      },
      "source": [
        "# 주성분해석2) PCA변환을 해석할 수 있는 또 다른 방법 \n",
        "# 테스트 포인트 (1x5,655)에 주성분의 전치행렬(5,655x100)을 곱하면 100개의 새로운 특성 값(PCA변환 뒤의 새로운 특성값)을 얻을 수 있음. \n",
        "# 이 새로운 특성값(1x100)에 주성분(100x5,655)을 곱하고 가중치 합으로 나타내면 원본 샘플(1x5,655)을 얻을 수 있음.\n",
        "# 결과, PCA변환 뒤의 얻은 새로운 특성값과 주성분의 가중치 합으로 원본 샘플을 표현할 수 있다. 라고 말할 수내는 데 필요한 수치 을 찾는 것으로 해석할 수 있음.\n",
        "from google.colab import files\n",
        "uploaded = files.upload() # 파일 업로드 기능 실행\n",
        "\n",
        "for fn in uploaded.keys(): # 업로드된 파일 정보 출력\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZtLRQqDNaEx"
      },
      "source": [
        "\n",
        "from IPython.display import Image\n",
        "Image('PCA.PNG')\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma_fj1s2No6j"
      },
      "source": [
        "# 주성분해석3) PCA모델을 이해하는 또 다른 방법 (몇 개의 주성분을 사용해 원본 데이터를 재구성해보는 것)\n",
        "# 예) 얼굴 이미지 데이터셋에서 몇 개의 주성분으로 데이터를 줄이고 원래 공간으로 되돌릴 수 있음.\n",
        "\n",
        "# 주성분 개수에 따른 세 얼굴 이미지의 재구성\n",
        "# 10,50,100,500개의 주성분을 사용해 얼굴 이미지를 재구성한 것\n",
        "# 예) 주성분을 10개만 사용 (얼굴의 각도, 조명 같은 이미지의 기본 요소만 나타남)\n",
        "# 예) 주성분을 더 많이 사용할수록 이미지가 더욱 상세해짐. 주성분을 픽셀 수 만큼 사용하면 이미지 완벽 재구성\n",
        "mglearn.plots.plot_pca_faces(X_train,X_test,image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z6gcBLs75ID"
      },
      "source": [
        "# PCA의 2개 주성분만을 이용해서 전체 데이터를 누구의 얼굴인지 클래스로 구분해서 산점도에 나타내봄\n",
        "mglearn.discrete_scatter(X_train_pca[:,0],X_train_pca[:,1],y_train)\n",
        "plt.xlabel(\"PCA1\")\n",
        "plt.ylabel(\"PCA2\")\n",
        "# 2개의 주성분만 사용하면 전체 데이터가 한 덩어리로 뭉쳐 있어 클래스가 잘 구분되지 않는 다는 것을 알 수 있음.\n",
        "# 예) 10개의 주성분을 사용해도 PCA는 얼굴의 아주 대략적인 특징만 잡았기 때문에 아래 그래프는 당연함."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDQ9y70l9QMW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}