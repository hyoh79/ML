{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SL(cancer classification).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMtm/2gX4+fTaI3urdyTf4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyoh79/ML/blob/main/SL(cancer_classification).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAOVLjfbuiOq"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer=load_breast_cancer()\n",
        "print(\"cancer.keys():\\n\",cancer.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cUpttaEvu28"
      },
      "source": [
        "print(\"유방암 데이터의 형태:\",cancer.data.shape)\n",
        "print(\"유방암 데이터의 형태(또 다른 명령어 표현)\", cancer['data'].shape)\n",
        "print(\"유방암 데이터의 타입:\", type(cancer)) # load_breat_cancer( )가 반환한 cancer 객체는 파이썬 딕셔너리와 유사한 Bunch 클래스의 객체로 키(keys)와 값(value)으로 구성되어 있기 때문"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inssj4Vav7H3"
      },
      "source": [
        "import numpy as np\n",
        "print(\"클래스별 샘플 개수:\\n\",{n:v for n,v in zip(cancer.target_names,np.bincount(cancer.target))})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc39uhkN0HNT"
      },
      "source": [
        "print(\"특성 이름:\\n\",cancer.feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_uyPOUf0o06"
      },
      "source": [
        "print(\"데이터 정보:\\n\",cancer.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvOoTX4k08j0"
      },
      "source": [
        "print(cancer.data.shape)\n",
        "print(cancer['feature_names'])\n",
        "print(cancer['data'][:5])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtKHJkgPeXTk"
      },
      "source": [
        "print(\"cancer['data']=\",cancer['data'])\n",
        "print(\"cancer['target']=\",cancer['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sRt3tw255Hz"
      },
      "source": [
        "print(cancer['target'])\n",
        "print(type(cancer['target']))\n",
        "print(cancer.target.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moz0ak8PUN3x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK7CJzyi3JLg"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=66)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer['data'],cancer['target'],stratify=cancer.target,random_state=66)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js_VHdFZUo-A"
      },
      "source": [
        "import pandas as pd\n",
        "!pip install mglearn\n",
        "\n",
        "import mglearn\n",
        "\n",
        "cancer_dataframe=pd.DataFrame(X_train, columns=cancer.feature_names)\n",
        "pd.plotting.scatter_matrix(cancer_dataframe, c=y_train, figsize=(15,15),marker='o',hist_kwds={'bins':20},s=60,alpha=.8,cmap=mglearn.cm3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R7X1A8OIaxH"
      },
      "source": [
        "training_accuracy=[]\n",
        "test_accuracy=[]\n",
        "\n",
        "neighbors_settings=range(1,11) #1에서 10까지 n_neighbors를 적용\n",
        "\n",
        "## [Algorithm#1: kNN for classification]\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "for n_neighbors in neighbors_settings:\n",
        "  clf=KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "  clf.fit(X_train, y_train)\n",
        "  training_accuracy.append(clf.score(X_train,y_train))\n",
        "  test_accuracy.append(clf.score(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XrwIKvGUGRt"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "plt.plot(neighbors_settings,training_accuracy,label=\"Trainig Accuracy\")\n",
        "plt.plot(neighbors_settings, test_accuracy, label=\"Test Accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"# of neighbors\")\n",
        "plt.legend()\n",
        "# 이웃을 하나 선택했을때 결정경계가 훈련 데이터에 가깝게 따라감(복잡한 모델, 과대적합). \n",
        "# 이웃의 수를 늘릴수록 결정 경계는 더 부드러워짐(단순한 모델을 의미).\n",
        "# cancer dataset으로 kNN에서 이웃의 수를 변화시켜보면서 모델의 복잡도와 일반화 사이의 관계를 입증해볼 수 있음."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEjbqRNQhzYU"
      },
      "source": [
        "## [Algorithm#2: Logistic Regression for classification]\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg=LogisticRegression(max_iter=5000).fit(X_train,y_train)\n",
        "\n",
        "print(\"훈련 세트 점수: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
        "print(\"테스트 세트 점수: {:.3f}\".format(logreg.score(X_test,y_test)))\n",
        "# 기본값 C=1이 훈련세트와 테스트 세트 양쪽에 95% 정확도로 꽤 훌륭한 성능을 내고 있지만\n",
        "# 훈련세트와 테스트 세트의 성능이 매우 비슷 (과소적합)--> 해결책(모델의 regularization-제약/규제을 더 풀어주기 위해 C를 증가시켜볼것!)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVwZRoh696wb"
      },
      "source": [
        "\n",
        "logreg100=LogisticRegression(C=100,max_iter=50000).fit(X_train,y_train) # C를 증가시킴(복잡도를 높인 모델, 성능이 좋음)\n",
        "\n",
        "print(\"훈련 세트 점수: {:.3f}\".format(logreg100.score(X_train, y_train)))\n",
        "print(\"테스트 세트 점수: {:.3f}\".format(logreg100.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcY-jRqE-DQG"
      },
      "source": [
        "\n",
        "logreg001=LogisticRegression(C=0.01,max_iter=50000).fit(X_train,y_train) \n",
        "# C를 감소시킴.(regularization-규제를 높인 모델, 이미 과소적합된 모델에서 규제를 더 높였기에 기본 매개변수 C=1일때보다 성능이 낮아짐)\n",
        "\n",
        "print(\"훈련 세트 점수: {:.3f}\".format(logreg001.score(X_train, y_train)))\n",
        "print(\"테스트 세트 점수: {:.3f}\".format(logreg001.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nb6EThtXNyl"
      },
      "source": [
        "# 유방암 데이터셋에 각기 다른 C값을 사용하여 만든 로지스틱 회귀의 계수 (예: L2규제)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(logreg100.coef_.T, '^', label=\"C=100\")\n",
        "plt.plot(logreg.coef_.T,'o',label=\"C=1\")\n",
        "plt.plot(logreg001.coef_.T,'v',label=\"C=0.001\")\n",
        "\n",
        "plt.xticks(range(cancer.data.shape[1]),cancer.feature_names, rotation=90)\n",
        "\n",
        "xlims=plt.xlim()\n",
        "plt.hlines(0,xlims[0],xlims[1])\n",
        "plt.xlim(xlims)\n",
        "plt.ylim(-5,5)\n",
        "\n",
        "plt.ylabel(\"Coefficients of the trained model\")\n",
        "plt.xlabel(\"Features\")\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmz6Xaq8fzdP"
      },
      "source": [
        "# 유방암 데이터셋에 각기 다른 C값을 사용하여 만든 로지스틱 회귀의 계수 (예: L1규제)\n",
        "for C, marker in zip([0.001,1,100],['o','^','v']):\n",
        "  lr_l1=LogisticRegression(solver='liblinear',C=C,penalty=\"l1\",max_iter=1000).fit(X_train,y_train)\n",
        "  print(\"C={:.3f}인 로지스틱 회귀의 훈련 정확도:{:.2f}\".format(C,lr_l1.score(X_train,y_train)))\n",
        "  print(\"C={:.3f}인 로지스틱 회귀의 훈련 정확도:{:.2f}\".format(C,lr_l1.score(X_test,y_test)))\n",
        "  plt.plot(lr_l1.coef_.T, marker, label=\"C={:.3f}\".format(C))\n",
        "\n",
        "  plt.xticks(range(cancer.data.shape[1]),cancer.feature_names,rotation=90)\n",
        "  xlims=plt.xlim()\n",
        "  plt.hlines(0,xlims[0],xlims[1])\n",
        "  plt.xlim(xlims)\n",
        "  plt.xlabel(\"Features\")\n",
        "  plt.ylabel(\"Coefficients of the trained model\")\n",
        "\n",
        "  plt.ylim(-5,5)\n",
        "  plt.legend(loc=3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOyAORaHEvoe"
      },
      "source": [
        "## [Algorithm#3: (kernel) SVC for classification]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(cancer.data,cancer.target,random_state=0)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "svc= SVC()\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "print(\"훈련 세트 정확도: {:.2f}\".format(svc.score(X_train,y_train)))\n",
        "print(\"테스트 세트 정확도:{:.2f}\".format(svc.score(X_test,y_test)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuRafuYtGkL_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.boxplot(X_train, manage_ticks=False)\n",
        "plt.yscale(\"symlog\")\n",
        "plt.xlabel(\"Feature list\")\n",
        "plt.ylabel(\"Feature size\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DjmFCdD9W7y"
      },
      "source": [
        "# 훈련 세트에서 특성별 최솟값 계산\n",
        "min_on_training=X_train.min(axis=0)\n",
        "\n",
        "# 훈련 세트에서 특성별 (최댓값-최솟값) 범위 계산\n",
        "range_on_training=(X_train-min_on_training).max(axis=0)\n",
        "\n",
        "\n",
        "# 훈련 데이터에서 최솟값을 빼고 범위로 나누면\n",
        "# 각 특성에 대해 최솟값은 0 최댓값은 1입니다\n",
        "X_train_scaled=(X_train-min_on_training) / range_on_training\n",
        "print(\"특성별 최솟값\\n\", X_train_scaled.min(axis=0))\n",
        "print(\"특성별 최댓값\\n\", X_train_scaled.max(axis=0))\n",
        "\n",
        "# 테스트 세트에도 같은 작업을 적용하지만\n",
        "# 훈련 세트에서 계산한 최솟값과 범위를 사용해야함. (Chap.3)\n",
        "X_test_scaled=(X_test-min_on_training)/range_on_training\n",
        "\n",
        "svc=SVC()\n",
        "svc.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"훈련 세트 정확도: {:.3f}\".format(svc.score(X_train_scaled,y_train)))\n",
        "print(\"테스트 세트 정확도: {:.3f}\".format(svc.score(X_test_scaled,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irMQ4zucUHrN"
      },
      "source": [
        "# C나 gamma값을 증가시켜 좀 더 복잡한 모델을 만들 수 있음.\n",
        "svc=SVC(C=1000)\n",
        "svc.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"훈련 세트 정확도: {:.3f}\".format(svc.score(X_train_scaled,y_train)))\n",
        "print(\"테스트 세트 정확도: {:.3f}\".format(svc.score(X_test_scaled,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "092UbeuGU_0K"
      },
      "source": [
        "# C나 gamma값을 감소시켜 좀 더 규제를 강하게 함.\n",
        "svc=SVC(C=000.1)\n",
        "svc.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"훈련 세트 정확도: {:.3f}\".format(svc.score(X_train_scaled,y_train)))\n",
        "print(\"테스트 세트 정확도: {:.3f}\".format(svc.score(X_test_scaled,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR5-d2jpJ6cu"
      },
      "source": [
        "## [Algorithm#4: Decision Tree for classification]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipAuFbL_6C9s"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree=DecisionTreeClassifier(random_state=0)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "print(\"훈련 세트 정확도: {:.3f}\",format(tree.score(X_train,y_train)))\n",
        "print(\"테스트 세트 정확도: {:.3f}\",format(tree.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G98X1RBlY_Dd"
      },
      "source": [
        "tree=DecisionTreeClassifier(max_depth=3,random_state=0)\n",
        "tree.fit(X_train,y_train)\n",
        "\n",
        "print(\"훈련 세트 정확도: {:.3f}\", format(tree.score(X_train,y_train)))\n",
        "print(\"테스트 세트 정확도: {:3f}\", format(tree.score(X_test,y_test)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBMmMvUNZxn-"
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "export_graphviz(tree,out_file=\"tree.dot\",class_names=[\"악성\",\"양성\"], feature_names=cancer.feature_names, impurity=False,filled=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T22jKROaayHR"
      },
      "source": [
        "import graphviz\n",
        "with open(\"tree.dot\") as f:\n",
        "  dot_graph=f.read()\n",
        "display(graphviz.Source(dot_graph))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WmrPsNkbFno"
      },
      "source": [
        "print(\"특성 중요도\\n\", tree.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa9aPcW6bPAZ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_feature_importances_cancer(model):\n",
        "  n_features=cancer.data.shape[1]\n",
        "  print(\"n_features:\",n_features)\n",
        "  plt.barh(np.arange(n_features),model.feature_importances_,align='center')\n",
        "  print(\"model.feature_importances_:\",model.feature_importances_)\n",
        "  plt.yticks(np.arange(n_features),cancer.feature_names)\n",
        "  plt.xlabel(\"feature_importances\")\n",
        "  plt.ylabel(\"feature\")\n",
        "  plt.ylim(-1,n_features)\n",
        "\n",
        "plot_feature_importances_cancer(tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRGvgqCpcHiz"
      },
      "source": [
        "# !pip install mglearn\n",
        "\n",
        "# import mglearn\n",
        "\n",
        "tree=mglearn.plots.plot_tree_not_monotone()\n",
        "display(tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL0eoFNAdlhu"
      },
      "source": [
        "## [Algorithm#5-1.1: Random Forest for classification]\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# 생성할 트리의 개수를 정해야함, n_estimators=100\n",
        "forest=RandomForestClassifier(n_estimators=100,random_state=0)\n",
        "forest.fit(X_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJk7B02okWyb"
      },
      "source": [
        "# Random Forest는 아무런 매개변수튜닝없이도 linear model, Decision Tree보다 높은 정확도를 냄.\n",
        "# 기본적으로 좋은 성능을 냄\n",
        "# cacer dataset\n",
        "print(\"훈련 세트 정확도:{:.3f}\".format(forest.score(X_train,y_train)))\n",
        "print(\"테스트 세트 정확도:{:.3f}\".format(forest.score(X_test,y_test)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npvEEguXkzm-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyRw7NbblKCn"
      },
      "source": [
        "# 유방암 데이터로 만든 Random Forest Model의 특성 중요도 (각 트리의 특성 중요도를 취합하여 계산한것)\n",
        "# Random Forest에서 제공하는 특성 중요도가 하나의 트리에서 제공하는 것보다 신뢰도가 높음.\n",
        "# Radom은 알고리즘이 가능성 있는 많은 경우를 고려할 수 있도록 하므로 Random Forest가 단일 트리보다 더 넓은 시각으로 데이터를 바라볼 수 있음.\n",
        "plot_feature_importances_cancer(forest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgX2WGhU4Q_8"
      },
      "source": [
        "# n_estimators=10000를 증가시켜도 정확도에 변화가 없음.\n",
        "## [Algorithm#5-1.2: Random Forest for classification]\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# 생성할 트리의 개수를 정해야함, n_estimators=10000\n",
        "forest=RandomForestClassifier(n_estimators=10000,random_state=0)\n",
        "forest.fit(X_train,y_train)\n",
        "# Random Forest는 아무런 매개변수튜닝없이도 linear model, Decision Tree보다 높은 정확도를 냄.\n",
        "# 기본적으로 좋은 성능을 냄\n",
        "# cacer dataset\n",
        "print(\"훈련 세트 정확도:{:.3f}\".format(forest.score(X_train,y_train)))\n",
        "print(\"테스트 세트 정확도:{:.3f}\".format(forest.score(X_test,y_test)))\n",
        "\n",
        "# 유방암 데이터로 만든 Random Forest Model의 특성 중요도 (각 트리의 특성 중요도를 취합하여 계산한것)\n",
        "# Random Forest에서 제공하는 특성 중요도가 하나의 트리에서 제공하는 것보다 신뢰도가 높음.\n",
        "# Radom은 알고리즘이 가능성 있는 많은 경우를 고려할 수 있도록 하므로 Random Forest가 단일 트리보다 더 넓은 시각으로 데이터를 바라볼 수 있음.\n",
        "plot_feature_importances_cancer(forest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2atbnIWY5Qb"
      },
      "source": [
        "## [Algorithm#5-2: Random Forest for classification]- cancer dataset은 차원이 30이기에 forage dataset과 two moons dataset처럼 2차원 시각화 불가능!\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# 생성할 트리의 개수를 정해야함, n_estimators=5\n",
        "forest=RandomForestClassifier(n_estimators=5,random_state=0)\n",
        "forest.fit(X_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0xORWmnlMjr"
      },
      "source": [
        "\n",
        "# 다섯 개의 랜덤한 결정 트리의 결정 경계와 예측한 확률을 평균내어 만든 결정 경계\n",
        "fig,axes=plt.subplots(2,3,figsize=(20,10))\n",
        "for i,(ax,tree) in enumerate(zip(axes.ravel(), forest.estimators_)):\n",
        "  ax.set_title(\"Tree {}\".format(i))\n",
        "  mglearn.plots.plot_tree_partition(cancer['data'],cancer['target'],tree,ax=ax)\n",
        "\n",
        "\n",
        "mglearn.plots.plot_2d_separator(forest,cancer['data'],fill=True,ax=axes[-1,-1],alpha=.4)\n",
        "axes[-1,-1].set_title(\"Random Forest\")\n",
        "mglearn.discrete_scatter(cancer['data'][:,0],cancer['data'][:,1],cancer['target'])\n",
        "# Random Forest는 개개의 트리보다 덜 과대적합되고 훨씬 좋은 결정 경계를 생성.\n",
        "# 실제 application에서는 매우 많은 트리(예: 수백, 수천 개)를 사용하기 때문에 더 부드러운 결정 경계가 생성됨."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28M293UlZfKq"
      },
      "source": [
        "## [Algorithm#6: GradientBoosting for classification]\n",
        "# default(기본값)- 깊이:3, 트리: 100개, 학습률: 0.1\n",
        "# 과대적합 됨.\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test=train_test_split(cancer.data, cancer.target, random_state=0)\n",
        "gbrt=GradientBoostingClassifier(random_state=0)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt.score(X_train,y_train)))\n",
        "print(\"테스트 세트 정확도: {:.3f}\".format(gbrt.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZI_M8sbNwKN"
      },
      "source": [
        "# 과대적합을 줄이기 위해서 트리의 최대 깊이를 줄여 사전 가지치기를 강하게 하거나\n",
        "gbrt=GradientBoostingClassifier(random_state=0, max_depth=1)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt.score(X_train,y_train)))\n",
        "print(\"테스트 세트 정확도: {:.3f}\".format(gbrt.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJCnEPaoI7Lw"
      },
      "source": [
        "# 학습률을 낮출 수 있음.\n",
        "gbrt=GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt.score(X_train,y_train)))\n",
        "print(\"테스트 세트 정확도: {:.3f}\".format(gbrt.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLM_-lS2OEgQ"
      },
      "source": [
        "# 특성 중요도 시각화\n",
        "gbrt=GradientBoostingClassifier(random_state=0, max_depth=1)\n",
        "gbrt.fit(X_train, y_train)\n",
        "plot_feature_importances_cancer(gbrt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWgVB_vnRMxw"
      },
      "source": [
        "## [Algorithm#7: Bagging with LogisticRegression for classification]\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer=load_breast_cancer()\n",
        "Xc_train,Xc_test, yc_train, yc_test=train_test_split(cancer.data,cancer.target,random_state=0)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 배깅(중복을 허용한 랜덤 샘플링으로 만든 훈련 세트를 사용하여 분류기를 각기 다르게 학습시키는 방법)\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "# 배깅을 사용하여 cancer 데이터셋에 로지스틱 회귀 모델을 100개 훈련하여 앙상블함.\n",
        "# oob_score(out of bag, 오차)를 True로 지정하면 매개변수는 Boostraping에 포함되지 않은 샘플을 기반으로 훈련된 모델을 평가.\n",
        "# 결과, oob_score값을 통해 테스트 세트의 성능을 짐작할 수 있음.\n",
        "bagging=BaggingClassifier(LogisticRegression(), n_estimators=100, oob_score=True, n_jobs=-1, random_state=42)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LwfiRR5elCc"
      },
      "source": [
        "bagging.fit(Xc_train, yc_train)\n",
        "\n",
        "print(\"훈련 세트 정확도:{:.3f}\".format(bagging.score(Xc_train,yc_train)))\n",
        "print(\"테스트 세트 정확도:{:.3f}\".format(bagging.score(Xc_test,yc_test)))\n",
        "print(\"OOB 샘플의 정확도:{:.3f}\".format(bagging.oob_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gF_0CdFgnGW"
      },
      "source": [
        "## [Algorithm#8: Bagging with Decision Tree for classification]~ Random Forest를 사용하게 더 편리\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "bagging=BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, oob_score=True, n_jobs=-1, random_state=42)\n",
        "\n",
        "bagging.fit(Xc_train, yc_train)\n",
        "\n",
        "print(\"훈련 세트 정확도:{:.3f}\".format(bagging.score(Xc_train,yc_train)))\n",
        "print(\"테스트 세트 정확도:{:.3f}\".format(bagging.score(Xc_test,yc_test)))\n",
        "print(\"OOB 샘플의 정확도:{:.3f}\".format(bagging.oob_score_))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5K4B1KAlgxC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBUiggtllp1Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}